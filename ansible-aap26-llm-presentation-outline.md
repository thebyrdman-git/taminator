# Ansible Lightspeed AI Integration
## Presentation Deck Outline

**Target Audience:** Customer Technical & Business Stakeholders  
**Duration:** 45-60 minutes (with Q&A)  
**Format:** Architecture workshop or executive briefing

---

## Slide 1: Title Slide

**Title:** Ansible Automation Platform 2.6  
**Subtitle:** AI-Powered Automation with Ansible Lightspeed

**Presented by:**
- [Your Name], Technical Account Manager, Red Hat
- [Solution Architect Name], Solution Architect, Red Hat

**Date:** [Presentation Date]  
**Customer:** [Customer Name]

**Footer:** Red Hat Confidential - Customer Use Only

---

## Slide 2: Agenda

**Today's Discussion:**

1. Business Challenge & Opportunity (5 min)
2. Ansible Lightspeed Overview (10 min)
3. LLM Integration Architecture (15 min)
4. Deployment Options & Decision Framework (10 min)
5. Implementation Roadmap (5 min)
6. Q&A and Next Steps (15 min)

**Our Goal Today:**
Determine the best Ansible Lightspeed deployment approach for [Customer Organization] and agree on next steps.

---

## Slide 3: The Business Challenge

**What We're Hearing from Automation Teams:**

âŒ **Slow Development Cycles**
- "Writing playbooks from scratch takes too long"
- "Onboarding new team members takes weeks"

âŒ **Inconsistent Quality**
- "Every engineer codes differently"
- "Best practices aren't consistently applied"

âŒ **Knowledge Silos**
- "Expertise locked in a few senior engineers"
- "Documentation is always out of date"

âŒ **Growing Backlog**
- "We can't keep up with automation requests"
- "Manual processes still everywhere"

**Does this resonate with your team?**

---

## Slide 4: The Opportunity

**What if your automation engineers had an AI assistant that:**

âœ… Generates Ansible code from natural language descriptions  
âœ… Provides real-time best practices guidance  
âœ… Answers questions about Ansible syntax and modules  
âœ… Helps troubleshoot playbook issues instantly  
âœ… Learns your organization's coding patterns  

**This is Ansible Lightspeed in AAP 2.6**

---

## Slide 5: Ansible Lightspeed - What It Is

**An AI-Powered Intelligent Assistant for Ansible**

**Three Key Capabilities:**

1. **Code Generation**
   - Natural language â†’ Ansible playbooks
   - "Deploy nginx with SSL" â†’ Complete playbook with best practices

2. **Intelligent Q&A**
   - Ask questions about Ansible concepts
   - Get troubleshooting guidance
   - Understand module parameters and options

3. **Real-time Assistance**
   - VS Code integration for code completion
   - Context-aware suggestions while you code
   - Best practices enforcement

**Built into AAP 2.6 - not a separate tool**

---

## Slide 6: Demo / Use Case Examples

**Example 1: Code Generation**

**User:** "Create a playbook that deploys Apache web server with custom configuration, enables HTTPS, configures firewall rules, and sets up log rotation"

**Lightspeed:** [Shows generated playbook with proper structure, variables, handlers, best practices]

---

**Example 2: Troubleshooting**

**User:** "Why does my playbook run tasks every time even though nothing changed?"

**Lightspeed:** [Explains idempotency, identifies non-idempotent tasks, suggests fixes]

---

**Example 3: Learning**

**User:** "How do I use the aws_ec2 inventory plugin for dynamic inventory?"

**Lightspeed:** [Provides configuration example, explains parameters, suggests best practices]

---

## Slide 7: Early Adopter Results

**Measured Business Impact:**

ğŸ“Š **30-50% Faster Development**
- Playbook creation time cut in half
- Less time debugging syntax errors

ğŸ“Š **60% Reduction in Onboarding Time**
- New engineers productive in days, not weeks
- AI provides instant mentorship

ğŸ“Š **Improved Code Quality**
- Consistent best practices application
- Reduced security vulnerabilities

ğŸ“Š **Increased Adoption**
- Lower barrier to entry for automation
- More teams using Ansible effectively

**Source:** Early adopter customer reports (financial services, government, enterprise)

---

## Slide 8: Architecture Overview

**How It Works:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Automation Engineer             â”‚
â”‚                                  â”‚
â”‚  â€¢ AAP Web UI (chat interface) â”‚
â”‚  â€¢ VS Code + Ansible extension â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ansible Automation Platform 2.6 â”‚
â”‚ (on Red Hat OpenShift)          â”‚
â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Ansible Lightspeed      â”‚   â”‚
â”‚  â”‚ Intelligent Assistant   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ Secure API
              â”‚ (HTTPS/TLS)
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Provider                     â”‚
â”‚ (Choose deployment model)        â”‚
â”‚                                  â”‚
â”‚  â€¢ IBM watsonx Code Assistant   â”‚
â”‚  â€¢ Red Hat Enterprise Linux AI  â”‚
â”‚  â€¢ Red Hat OpenShift AI         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Point:** Requires specific LLM infrastructure from Red Hat or IBM

---

## Slide 9: LLM Integration - Important Constraints

**What's Supported in AAP 2.6:**

âœ… IBM watsonx Code Assistant (SaaS or Self-hosted)  
âœ… Red Hat Enterprise Linux AI (Self-hosted)  
âœ… Red Hat OpenShift AI (Platform)  

**What's NOT Supported:**

âŒ OpenAI (GPT-4, ChatGPT, etc.)  
âŒ Anthropic Claude  
âŒ Google Gemini  
âŒ Azure OpenAI Service  
âŒ AWS Bedrock  
âŒ Any other third-party LLM  

**Future:** Model Context Protocol (MCP) support is in tech preview - will enable broader LLM compatibility in future AAP releases.

**Why this matters:** Architecture and procurement planning must account for specific Red Hat/IBM infrastructure

---

## Slide 10: Deployment Option 1 - IBM watsonx SaaS

**Fully Managed Cloud Service**

**Architecture:**
- IBM Cloud-hosted LLM service
- Ansible-specific Granite models
- Managed by IBM (no infrastructure for you)

**Pros:**
- âš¡ **Fastest deployment:** 4-5 days to production
- ğŸ¯ **Best Ansible accuracy:** Purpose-trained for Ansible
- ğŸ”§ **Zero infrastructure:** IBM manages everything
- ğŸ“ˆ **Auto-scaling:** Handles usage spikes automatically

**Cons:**
- â˜ï¸ **Requires cloud connectivity:** Not for air-gapped
- ğŸŒ **Data leaves premises:** Processed in IBM Cloud
- ğŸ’° **Usage-based costs:** Variable monthly billing

**Best For:**
- Fast time to value
- Cloud-first strategies
- Standard security postures
- Organizations without AI infrastructure expertise

**Investment:** Subscription + usage fees | **Timeline:** 4-5 days

---

## Slide 11: Deployment Option 2 - RHEL AI (Self-Hosted)

**Self-Hosted Open-Source AI Platform**

**Architecture:**
- Dedicated RHEL 9.x server(s) in your data center
- Open-source Granite models via vLLM inference
- Complete data control

**Pros:**
- ğŸ”’ **Complete data sovereignty:** Nothing leaves your network
- ğŸš« **Air-gap compatible:** No internet required
- ğŸ’° **Predictable costs:** No per-token charges
- ğŸ¨ **Customizable:** Fine-tune models with InstructLab

**Cons:**
- ğŸ—ï¸ **Infrastructure required:** Servers + GPU recommended
- âš™ï¸ **Operational complexity:** You manage and maintain
- ğŸ•’ **Longer deployment:** 2-3 weeks to production
- ğŸ¤¹ **Requires expertise:** AI/ML operations knowledge

**Best For:**
- Data sovereignty requirements
- Air-gapped environments
- Regulated industries (finance, healthcare, government)
- Long-term deployments with high usage

**Investment:** RHEL AI subscription + infrastructure | **Timeline:** 2-3 weeks

---

## Slide 12: Deployment Option 3 - OpenShift AI Platform

**Enterprise MLOps Platform**

**Architecture:**
- OpenShift cluster with AI/ML capabilities
- Model serving infrastructure (KServe + vLLM)
- Granite models deployed as services

**Pros:**
- ğŸ¢ **Enterprise platform:** Supports multiple AI initiatives
- ğŸ“Š **MLOps built-in:** Model versioning, monitoring, governance
- ğŸ”„ **Multi-tenant:** Share infrastructure across teams
- ğŸ¯ **GPU optimization:** Efficient resource utilization

**Cons:**
- ğŸ—ï¸ **Significant infrastructure:** Full OpenShift cluster required
- ğŸ’° **Higher initial cost:** Platform + GPU nodes
- ğŸ•’ **Longer deployment:** 2-4 weeks if cluster doesn't exist
- ğŸ¤¹ **Complex operations:** OpenShift + AI expertise needed

**Best For:**
- Organizations with multiple AI initiatives
- Existing OpenShift investments
- Need for centralized AI governance
- Teams building custom ML models

**Investment:** OpenShift AI subscription + cluster infrastructure | **Timeline:** 2-4 weeks

---

## Slide 13: Deployment Decision Matrix

**Choosing the Right Option:**

| **Factor** | **watsonx SaaS** | **RHEL AI** | **OpenShift AI** |
|-----------|---------------|-----------|---------------|
| **Speed to Production** | ğŸŸ¢ Days | ğŸŸ¡ Weeks | ğŸŸ¡ Weeks |
| **Infrastructure Needed** | ğŸŸ¢ None | ğŸŸ¡ Moderate | ğŸ”´ Significant |
| **Ansible Accuracy** | ğŸŸ¢ Best | ğŸŸ¡ Good | ğŸŸ¡ Good |
| **Data Sovereignty** | ğŸ”´ IBM Cloud | ğŸŸ¢ Complete | ğŸŸ¢ Complete |
| **Air-gap Support** | ğŸ”´ No | ğŸŸ¢ Yes | ğŸŸ¢ Yes |
| **Operational Complexity** | ğŸŸ¢ Low | ğŸŸ¡ Moderate | ğŸ”´ High |
| **Cost Predictability** | ğŸŸ¡ Variable | ğŸŸ¢ Fixed | ğŸŸ¡ Fixed |

ğŸŸ¢ = Strong | ğŸŸ¡ = Moderate | ğŸ”´ = Consideration

---

## Slide 14: [Customer Name] - Recommended Approach

**Based on our understanding of [Customer Organization]:**

**Your Requirements:**
- [Requirement 1: e.g., Air-gapped environment]
- [Requirement 2: e.g., Data sovereignty for compliance]
- [Requirement 3: e.g., Existing OpenShift deployment]
- [Requirement 4: e.g., Timeline: Production in 60 days]

**Our Recommendation:** **[Option Name]**

**Why this fits:**
âœ… [Reason 1 aligned to their requirement]  
âœ… [Reason 2 aligned to their requirement]  
âœ… [Reason 3 aligned to their requirement]  

**Trade-offs to consider:**
âš ï¸ [Trade-off 1]  
âš ï¸ [Trade-off 2]  

**Alternative consideration:** [Brief mention of alternate if close call]

---

## Slide 15: Infrastructure Requirements (Self-Hosted)

**If Choosing RHEL AI or OpenShift AI:**

**Compute Requirements (Minimum):**
- 16 vCPU per inference server
- 64 GB RAM per inference server
- 500 GB storage for models and data
- RHEL 9.x or OpenShift 4.14+

**GPU Acceleration (Highly Recommended):**
- NVIDIA A100 (40GB) or H100 (80GB)
- 1-2 GPUs for small deployment (< 50 users)
- 3-4+ GPUs for medium deployment (50-200 users)
- GPU cluster for large deployment (200+ users)

**Network:**
- Low-latency connection to AAP 2.6
- HTTPS/TLS for API communication
- Bandwidth: 10 Gbps recommended

**Cost Estimate:**
- Hardware: $[X]K - $[Y]K (depending on GPU choice)
- Annual subscription: $[Z]K
- Operational costs: $[A]K annually

---

## Slide 16: Implementation Roadmap

**Proposed Timeline:**

**Phase 1: Planning & Approval (Weeks 1-2)**
- Week 1: Architecture finalization and approval
- Week 2: Procurement (subscriptions + hardware if needed)
- Week 2: Pilot team selection and kickoff

**Phase 2: Deployment (Weeks 3-6)**
- Weeks 3-4: Infrastructure deployment (if self-hosted)
- Week 5: Ansible Lightspeed configuration
- Week 6: Integration testing and validation

**Phase 3: Pilot Program (Weeks 7-12)**
- Week 7: Pilot launch with [X] engineers
- Weeks 8-11: Usage, feedback collection, optimization
- Week 12: Results analysis and ROI measurement

**Phase 4: Rollout (Month 4+)**
- Month 4: Expand to broader team (phased approach)
- Month 5+: Track ongoing value and optimization
- Continuous: Knowledge sharing and best practices

**Total time to pilot results:** ~12 weeks

---

## Slide 17: Success Metrics & ROI

**How We'll Measure Success:**

**Primary Metrics:**
- â±ï¸ **Time to develop automation:** Hours per playbook (target: -40%)
- ğŸ“š **Onboarding time:** Days to productivity (target: -60%)
- ğŸ› **Code quality:** Error rate, best practices compliance (target: +30%)
- ğŸ˜Š **User satisfaction:** Team adoption and feedback (target: 80%+ positive)

**Business Metrics:**
- ğŸ’° **Automation backlog reduction:** % decrease in pending requests
- ğŸš€ **Automation coverage:** % of infrastructure under automation
- ğŸ’¼ **Business value:** Revenue protected, cost avoided, time saved

**Expected ROI:**
- Break-even: [X] months
- Annual benefit: $[Y]K in productivity gains
- 3-year NPV: $[Z]K

**Case Study:** [Include brief example from similar customer if available]

---

## Slide 18: Security & Compliance

**Data Security:**

**For All Options:**
- ğŸ”’ TLS 1.3 encryption in transit
- ğŸ” API key authentication
- ğŸ“Š Audit logging enabled
- ğŸ‘¥ RBAC integration with AAP

**For Self-Hosted (RHEL AI / OpenShift AI):**
- ğŸ¢ All data stays within your environment
- ğŸ”’ Your encryption policies apply
- ğŸŒ No external data transmission
- ğŸ›¡ï¸ Your security controls govern access

**For IBM watsonx SaaS:**
- ğŸ¢ IBM Cloud security controls (SOC 2, ISO 27001)
- ğŸ”’ Data encrypted at rest in IBM infrastructure
- ğŸ“‹ GDPR and compliance certifications
- ğŸ¤ IBM Data Processing Agreement

**Compliance Assessment:**
[Table showing how each option meets specific customer compliance requirements]

---

## Slide 19: Risk Assessment & Mitigation

**Potential Risks & Mitigations:**

**Risk: AI generates incorrect or insecure code**
- âœ… Mitigation: Code review processes remain essential
- âœ… Mitigation: CI/CD testing validates all generated code
- âœ… Mitigation: Ansible Lint integration for quality checks

**Risk: Team adoption resistance**
- âœ… Mitigation: Start with champion users (pilot program)
- âœ… Mitigation: Training and enablement plan
- âœ… Mitigation: Highlight productivity gains and frustration reduction

**Risk: Infrastructure investment before ROI**
- âœ… Mitigation: Start with IBM watsonx SaaS (minimal investment)
- âœ… Mitigation: Pilot program validates value before scale
- âœ… Mitigation: Clear ROI metrics and timeline

**Risk: Vendor/technology lock-in**
- âœ… Mitigation: Open technologies (OpenShift, RHEL, open models)
- âœ… Mitigation: MCP support coming (broader LLM compatibility)
- âœ… Mitigation: Red Hat + IBM enterprise support

---

## Slide 20: Investment Summary

**Total Investment Overview:**

**Option 1: IBM watsonx SaaS**
- **Upfront:** $[X]K (subscription, setup)
- **Year 1:** $[Y]K total
- **Year 2-3:** $[Z]K annually
- **TCO (3-year):** $[Total]K

**Option 2: RHEL AI (Self-Hosted)**
- **Upfront:** $[X]K (hardware, subscription, services)
- **Year 1:** $[Y]K total
- **Year 2-3:** $[Z]K annually (subscription + ops)
- **TCO (3-year):** $[Total]K

**Option 3: OpenShift AI**
- **Upfront:** $[X]K (platform, GPU, subscription, services)
- **Year 1:** $[Y]K total
- **Year 2-3:** $[Z]K annually
- **TCO (3-year):** $[Total]K

**Expected ROI:**
- Productivity gains: $[X]K annually
- Break-even: [Y] months
- 3-year NPV: $[Z]K

---

## Slide 21: Comparison to Alternatives

**Why Not Just Use ChatGPT or Claude?**

âŒ **Not integrated with AAP:** Separate tool, context switching  
âŒ **Not Ansible-optimized:** Generic AI, not trained on Ansible  
âŒ **No code completion:** Can't help while you're coding  
âŒ **Compliance issues:** Data sent to external AI services  
âŒ **No governance:** Can't control or audit usage  

**Ansible Lightspeed Advantages:**

âœ… **Native AAP integration:** Built into the platform you already use  
âœ… **Ansible-specific training:** Best accuracy for Ansible code generation  
âœ… **IDE integration:** Real-time assistance while coding  
âœ… **Enterprise control:** Deploy on-premises, audit everything  
âœ… **Red Hat support:** Enterprise SLA and support model  

---

## Slide 22: What's Next - Pilot Program Proposal

**Proposed Pilot:**

**Scope:**
- Duration: 6-8 weeks
- Team: [10-20] automation engineers from [specific team/department]
- Environment: [Production / Non-production]
- Use cases: [Specific automation initiatives]

**Success Criteria:**
- 30%+ reduction in playbook development time
- 80%+ user satisfaction
- Zero security/compliance incidents
- Positive ROI demonstrated

**Deliverables:**
- Pilot report with metrics
- User feedback and recommendations
- Rollout plan for broader organization
- Lessons learned and optimizations

**Investment:**
- [Chosen option] deployment
- Red Hat services: [X] days
- Customer resources: [Y] people over [Z] weeks

---

## Slide 23: Immediate Next Steps

**Action Items:**

**Today (Before we leave this meeting):**
- [ ] Agree on recommended deployment option
- [ ] Identify pilot team and executive sponsor
- [ ] Confirm budget and timeline expectations

**This Week:**
- [ ] [Customer]: Assemble pilot team
- [ ] [Red Hat]: Prepare detailed architecture document
- [ ] [Customer]: Begin procurement process
- [ ] [Red Hat]: Schedule kickoff meeting

**Next 2 Weeks:**
- [ ] Finalize architecture and design
- [ ] Complete procurement
- [ ] Infrastructure planning (if self-hosted)
- [ ] Pilot team kickoff and training

**Weeks 3-6:**
- [ ] Deploy infrastructure
- [ ] Configure Ansible Lightspeed
- [ ] Begin pilot program

---

## Slide 24: Questions & Discussion

**Open Discussion:**

**Topics to Cover:**
- Any concerns or questions about deployment options?
- Security or compliance questions?
- Infrastructure sizing and requirements?
- Budget and procurement process?
- Pilot team composition and timeline?

**Our Commitment:**
- Architecture support throughout deployment
- Regular check-ins during pilot program
- Optimization and troubleshooting support
- Executive reporting and metrics

**Your Red Hat Team:**
- Technical Account Manager: [Name, contact]
- Solution Architect: [Name, contact]
- Account Executive: [Name, contact]

---

## Slide 25: Summary & Decision

**Key Takeaways:**

1. âœ… **Ansible Lightspeed delivers measurable value:** 30-50% productivity gains
2. âœ… **Three production-ready deployment options:** SaaS, RHEL AI, OpenShift AI
3. âœ… **Recommendation for [Customer]:** **[Chosen option]** based on your requirements
4. âœ… **Clear path forward:** Pilot program â†’ Broader rollout
5. âœ… **Red Hat support:** Architecture, implementation, ongoing optimization

**Decision Needed Today:**
- Approve recommended deployment option
- Commit to pilot program
- Assign executive sponsor and budget

**Timeline:**
- **Decision today** â†’ Production pilot in [X] weeks

**Next Meeting:**
- Kickoff: [Proposed date, 1-2 weeks]

---

## Slide 26: Thank You

**Contact Information:**

[Your Name]  
Technical Account Manager  
Red Hat  
ğŸ“§ [email]  
ğŸ“± [phone]  

[Solution Architect Name]  
Solution Architect  
Red Hat  
ğŸ“§ [email]  
ğŸ“± [phone]  

**Follow-up Materials:**
- Detailed technical integration guide
- Customer decision brief (15 pages)
- Architecture diagrams
- Custom quote and timeline

**Thank you for your time!**

Questions?

---

## APPENDIX SLIDES (As Needed)

### Appendix A: Detailed Architecture Diagram
[Full technical architecture with all components]

### Appendix B: Hardware Specifications
[Detailed specs for self-hosted options]

### Appendix C: Model Comparison
[Granite model variants and capabilities]

### Appendix D: Security Deep Dive
[Detailed security controls and compliance mapping]

### Appendix E: API and Integration Details
[Technical integration points and APIs]

### Appendix F: Competitive Comparison
[How this compares to other AI coding assistants]

### Appendix G: Case Studies
[2-3 customer success stories with metrics]

### Appendix H: FAQ
[Common questions and answers]

---

## Presenter Notes

### Slide-by-Slide Tips

**Slides 1-4:** Set the context, establish pain points (5 minutes)
- Ask customer about their current challenges
- Get agreement that these are real problems for them

**Slides 5-7:** Show the solution and value (10 minutes)
- Demo if possible (screen share or recording)
- Focus on "wow factor" - this is significantly better than status quo

**Slides 8-9:** Technical reality check (5 minutes)
- Be honest about constraints (no direct OpenAI, etc.)
- Position as strategic vs. tactical limitation

**Slides 10-13:** Deployment options (15 minutes)
- Go deep on pros/cons for each
- Watch body language for which resonates
- Ask clarifying questions about requirements

**Slide 14:** Make recommendation (5 minutes)
- Be confident but open to discussion
- Tie directly to their stated requirements

**Slides 15-19:** Details and planning (10 minutes)
- Cover infrastructure, timeline, security based on chosen option
- Answer questions as they arise

**Slides 20-22:** Business case and next steps (5 minutes)
- Reinforce ROI and value
- Create urgency for decision

**Slides 23-25:** Close and commit (10 minutes)
- Get concrete commitments
- Schedule follow-up meetings
- Assign action items

**Slide 26:** Thank you and wrap (2 minutes)

### Customization Checklist

Before presenting:
- [ ] Replace all [Customer Name] placeholders
- [ ] Update timeline estimates based on customer requirements
- [ ] Insert actual cost estimates (work with Red Hat sales)
- [ ] Add customer-specific requirements to Slide 14
- [ ] Prepare demo or screenshots for Slide 6
- [ ] Customize risk mitigation for customer's concerns
- [ ] Add relevant case study to appendix
- [ ] Update contact information
- [ ] Review with Solution Architect for technical accuracy
- [ ] Practice timing (aim for 45 minutes + 15 min Q&A)

---

*Presentation Deck Outline for Ansible AAP 2.6 Lightspeed Customer Workshops*  
*Red Hat TAM Enablement - October 2025*

