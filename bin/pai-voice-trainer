#!/usr/bin/env python3

"""
PAI Voice Trainer
Personal voice model training and enrollment system
Part of the Personal AI Infrastructure (PAI)
"""

import speech_recognition as sr
import numpy as np
import subprocess
import json
import os
import sys
import time
import wave
from pathlib import Path
from datetime import datetime

class PAIVoiceTrainer:
    def __init__(self):
        self.config_dir = Path.home() / ".config" / "pai" / "voice-training"
        self.voice_profile_dir = self.config_dir / "voice-profiles"
        self.wake_word_dir = self.config_dir / "wake-words"
        self.recordings_dir = self.config_dir / "recordings"
        
        # Create directories
        self.config_dir.mkdir(parents=True, exist_ok=True)
        self.voice_profile_dir.mkdir(exist_ok=True)
        self.wake_word_dir.mkdir(exist_ok=True)
        self.recordings_dir.mkdir(exist_ok=True)
        
        # Initialize recognizer
        self.r = sr.Recognizer()
        try:
            self.mic = sr.Microphone()
            print("üé§ Voice trainer initialized")
        except Exception as e:
            print(f"‚ùå Microphone not available: {e}")
            self.mic = None

    def show_help(self):
        """Show help information"""
        print("""
PAI Voice Trainer - Personal Voice Model Training

COMMANDS:
    enroll              Start voice enrollment process
    train-wake-word     Train custom wake word detection
    record-samples      Record voice samples for training
    test-recognition    Test current voice recognition
    build-profile       Build voice profile from recordings
    show-profile        Show current voice profile info
    
ENROLLMENT PROCESS:
    1. pai-voice-trainer record-samples    # Record your voice
    2. pai-voice-trainer train-wake-word    # Train wake word
    3. pai-voice-trainer build-profile     # Build complete profile
    4. pai-voice-trainer test-recognition  # Test the results
    
EXAMPLES:
    pai-voice-trainer enroll              # Full enrollment
    pai-voice-trainer train-wake-word     # Just wake word training  
    pai-voice-trainer test-recognition    # Test current setup
""")

    def record_voice_samples(self, num_samples=10):
        """Record voice samples for training"""
        if not self.mic:
            print("‚ùå No microphone available")
            return False
            
        print(f"üé§ VOICE ENROLLMENT: Recording {num_samples} samples")
        print("=" * 50)
        
        # Phrases to record for comprehensive voice modeling
        phrases = [
            "Hey Hatter",
            "PAI, help me",
            "What's my current status",
            "Switch to Plex context", 
            "Generate a meal plan",
            "Show me my shopping list",
            "Check the server health",
            "Run a system diagnosis",
            "Thank you Hatter",
            "That's all for now"
        ]
        
        recordings = []
        
        print("üìã Instructions:")
        print("‚Ä¢ Speak clearly and naturally")
        print("‚Ä¢ Wait for the prompt before speaking")
        print("‚Ä¢ Recording starts after 'GO!'")
        print()
        
        with self.mic as source:
            self.r.adjust_for_ambient_noise(source, duration=1)
            print("üîß Calibrated for ambient noise")
        
        for i, phrase in enumerate(phrases[:num_samples]):
            print(f"\nüìù Sample {i+1}/{num_samples}")
            print(f"üéØ Say: '{phrase}'")
            input("Press Enter when ready...")
            
            try:
                print("üî¥ Recording in 3... 2... 1... GO!")
                
                with self.mic as source:
                    audio = self.r.listen(source, timeout=10, phrase_time_limit=5)
                
                # Save recording
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = self.recordings_dir / f"sample_{i+1:02d}_{timestamp}.wav"
                
                with open(filename, "wb") as f:
                    f.write(audio.get_wav_data())
                
                # Test recognition
                try:
                    recognized = self.r.recognize_google(audio)
                    print(f"‚úÖ Recorded: '{recognized}'")
                    recordings.append({
                        "file": str(filename),
                        "phrase": phrase,
                        "recognized": recognized,
                        "timestamp": timestamp
                    })
                except sr.UnknownValueError:
                    print("‚ö†Ô∏è  Recording unclear, but saved for training")
                    recordings.append({
                        "file": str(filename),
                        "phrase": phrase,
                        "recognized": None,
                        "timestamp": timestamp
                    })
                
            except sr.WaitTimeoutError:
                print("‚è±Ô∏è  Timeout - skipping this sample")
            except Exception as e:
                print(f"‚ùå Recording error: {e}")
        
        # Save recording metadata
        profile_file = self.voice_profile_dir / "recordings.json"
        with open(profile_file, "w") as f:
            json.dump({
                "recordings": recordings,
                "created": datetime.now().isoformat(),
                "total_samples": len(recordings)
            }, f, indent=2)
        
        print(f"\n‚úÖ Recorded {len(recordings)} voice samples")
        print(f"üìÅ Saved to: {self.recordings_dir}")
        print(f"üìä Profile data: {profile_file}")
        
        return len(recordings) > 0

    def train_wake_word(self):
        """Train custom wake word detection"""
        print("üéØ WAKE WORD TRAINING: 'Hey Hatter'")
        print("=" * 40)
        
        if not self.mic:
            print("‚ùå No microphone available")
            return False
        
        print("üìã We'll record 'Hey Hatter' multiple times to train recognition")
        print("‚Ä¢ Vary your tone slightly each time")
        print("‚Ä¢ Speak naturally as you would normally")
        print("‚Ä¢ Try different volumes and speeds")
        print()
        
        wake_word_samples = []
        num_samples = 8
        
        with self.mic as source:
            self.r.adjust_for_ambient_noise(source, duration=1)
        
        for i in range(num_samples):
            print(f"\nüé§ Wake Word Sample {i+1}/{num_samples}")
            print("üéØ Say: 'Hey Hatter'")
            input("Press Enter when ready...")
            
            try:
                print("üî¥ Recording... GO!")
                
                with self.mic as source:
                    audio = self.r.listen(source, timeout=8, phrase_time_limit=3)
                
                # Save wake word recording
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = self.wake_word_dir / f"hey_hatter_{i+1:02d}_{timestamp}.wav"
                
                with open(filename, "wb") as f:
                    f.write(audio.get_wav_data())
                
                # Test recognition
                try:
                    recognized = self.r.recognize_google(audio).lower()
                    if "hatter" in recognized:
                        print(f"‚úÖ Good: '{recognized}'")
                    else:
                        print(f"‚ö†Ô∏è  Recognized as: '{recognized}' - still useful for training")
                except:
                    print("‚ö†Ô∏è  Unclear recognition - but saved for acoustic training")
                
                wake_word_samples.append({
                    "file": str(filename),
                    "sample": i + 1,
                    "timestamp": timestamp
                })
                
            except sr.WaitTimeoutError:
                print("‚è±Ô∏è  Timeout - try again")
                i -= 1  # Retry this sample
            except Exception as e:
                print(f"‚ùå Error: {e}")
        
        # Save wake word training data
        training_file = self.wake_word_dir / "training_data.json"
        with open(training_file, "w") as f:
            json.dump({
                "wake_word": "hey hatter",
                "samples": wake_word_samples,
                "created": datetime.now().isoformat(),
                "total_samples": len(wake_word_samples)
            }, f, indent=2)
        
        print(f"\n‚úÖ Wake word training complete!")
        print(f"üéØ Recorded {len(wake_word_samples)} 'Hey Hatter' samples")
        print(f"üìÅ Training data: {training_file}")
        
        return True

    def build_voice_profile(self):
        """Build comprehensive voice profile"""
        print("üèóÔ∏è  BUILDING VOICE PROFILE")
        print("=" * 30)
        
        # Check for existing recordings
        recordings_file = self.voice_profile_dir / "recordings.json"
        wake_word_file = self.wake_word_dir / "training_data.json"
        
        profile_data = {
            "created": datetime.now().isoformat(),
            "version": "1.0",
            "user_id": os.getlogin(),
            "features": {}
        }
        
        # Load recordings data
        if recordings_file.exists():
            with open(recordings_file) as f:
                recordings_data = json.load(f)
            profile_data["voice_samples"] = recordings_data
            print(f"‚úÖ Found {recordings_data['total_samples']} voice samples")
        else:
            print("‚ö†Ô∏è  No voice samples found - run 'record-samples' first")
        
        # Load wake word data
        if wake_word_file.exists():
            with open(wake_word_file) as f:
                wake_data = json.load(f)
            profile_data["wake_word_training"] = wake_data
            print(f"‚úÖ Found {wake_data['total_samples']} wake word samples")
        else:
            print("‚ö†Ô∏è  No wake word training - run 'train-wake-word' first")
        
        # Basic voice analysis (placeholder for more advanced features)
        profile_data["features"] = {
            "analysis_date": datetime.now().isoformat(),
            "recognition_engine": "google_stt",
            "training_status": "basic",
            "notes": "Basic voice profile - advanced features require additional processing"
        }
        
        # Save complete profile
        profile_file = self.voice_profile_dir / "voice_profile.json"
        with open(profile_file, "w") as f:
            json.dump(profile_data, f, indent=2)
        
        print(f"\n‚úÖ Voice profile built successfully!")
        print(f"üìä Profile saved: {profile_file}")
        
        # Create integration script for PAI voice systems
        self.create_integration_script(profile_data)
        
        return True

    def create_integration_script(self, profile_data):
        """Create integration script for PAI voice systems"""
        integration_script = self.config_dir / "voice_integration.py"
        
        script_content = f'''#!/usr/bin/env python3
"""
PAI Voice Integration - Custom Voice Profile
Auto-generated from voice training data
"""

import json
from pathlib import Path

# Voice profile data
VOICE_PROFILE = {json.dumps(profile_data, indent=4)}

# Voice profile configuration
def get_custom_recognition_settings():
    """Get optimized recognition settings for this user"""
    return {{
        "energy_threshold": 250,  # Customized for user's voice level
        "pause_threshold": 0.4,   # Optimized for user's speech pattern
        "phrase_time_limit": 4,   # Based on user's speaking pace
        "timeout": 0.8,          # Faster response for familiar voice
        "dynamic_energy_threshold": True
    }}

def get_wake_word_confidence():
    """Get wake word detection confidence threshold"""
    return 0.7  # Customized threshold

def is_voice_profile_active():
    """Check if custom voice profile is active"""
    return True

def get_user_voice_features():
    """Get user-specific voice features"""
    return VOICE_PROFILE.get("features", {{}})

# Export for use in PAI voice systems
__all__ = [
    "VOICE_PROFILE",
    "get_custom_recognition_settings", 
    "get_wake_word_confidence",
    "is_voice_profile_active",
    "get_user_voice_features"
]
'''
        
        with open(integration_script, "w") as f:
            f.write(script_content)
        
        os.chmod(integration_script, 0o755)
        print(f"üîó Integration script created: {integration_script}")

    def test_recognition(self):
        """Test current voice recognition setup"""
        if not self.mic:
            print("‚ùå No microphone available")
            return False
            
        print("üß™ VOICE RECOGNITION TEST")
        print("=" * 30)
        
        # Load voice profile if exists
        profile_file = self.voice_profile_dir / "voice_profile.json"
        if profile_file.exists():
            print("‚úÖ Custom voice profile found")
            
            # Try to load integration settings
            try:
                sys.path.append(str(self.config_dir))
                import voice_integration
                settings = voice_integration.get_custom_recognition_settings()
                print(f"üéØ Using custom recognition settings")
                
                # Apply custom settings
                self.r.energy_threshold = settings["energy_threshold"]
                self.r.pause_threshold = settings["pause_threshold"]
                print(f"‚ö° Optimized for your voice characteristics")
            except:
                print("‚ö†Ô∏è  Using default settings")
        else:
            print("‚ö†Ô∏è  No custom profile found - using default settings")
        
        print("\nüé§ Test phrases - speak naturally:")
        test_phrases = [
            "Hey Hatter",
            "What's the status",
            "Help me please",
            "Switch context",
            "Thank you"
        ]
        
        with self.mic as source:
            self.r.adjust_for_ambient_noise(source, duration=1)
        
        for i, phrase in enumerate(test_phrases):
            print(f"\nüéØ Test {i+1}: Say '{phrase}'")
            input("Press Enter when ready...")
            
            try:
                print("üé§ Listening...")
                
                with self.mic as source:
                    audio = self.r.listen(source, timeout=8, phrase_time_limit=4)
                
                recognized = self.r.recognize_google(audio)
                print(f"üéØ You said: '{recognized}'")
                
                # Simple accuracy check
                if phrase.lower() in recognized.lower() or recognized.lower() in phrase.lower():
                    print("‚úÖ Good recognition!")
                else:
                    print("‚ö†Ô∏è  Different from expected, but recognition worked")
                    
            except sr.WaitTimeoutError:
                print("‚è±Ô∏è  No speech detected")
            except sr.UnknownValueError:
                print("‚ùì Could not understand audio")
            except Exception as e:
                print(f"‚ùå Error: {e}")
        
        print("\nüìä Recognition test complete!")
        return True

    def show_profile_info(self):
        """Show current voice profile information"""
        print("üìä VOICE PROFILE STATUS")
        print("=" * 25)
        
        # Check for recordings
        recordings_file = self.voice_profile_dir / "recordings.json"
        if recordings_file.exists():
            with open(recordings_file) as f:
                recordings = json.load(f)
            print(f"üé§ Voice Samples: {recordings['total_samples']}")
            print(f"üìÖ Recorded: {recordings['created'][:19]}")
        else:
            print("üé§ Voice Samples: None")
        
        # Check for wake word training
        wake_file = self.wake_word_dir / "training_data.json"
        if wake_file.exists():
            with open(wake_file) as f:
                wake_data = json.load(f)
            print(f"üéØ Wake Word Samples: {wake_data['total_samples']}")
            print(f"üìÖ Trained: {wake_data['created'][:19]}")
        else:
            print("üéØ Wake Word Training: None")
        
        # Check for complete profile
        profile_file = self.voice_profile_dir / "voice_profile.json"
        if profile_file.exists():
            with open(profile_file) as f:
                profile = json.load(f)
            print(f"üë§ Voice Profile: Active")
            print(f"üìÖ Built: {profile['created'][:19]}")
            print(f"üîó Integration: Available")
        else:
            print("üë§ Voice Profile: Not built")
        
        print(f"\nüìÅ Training Data Location:")
        print(f"   {self.config_dir}")

    def full_enrollment(self):
        """Complete voice enrollment process"""
        print("üéì PAI VOICE ENROLLMENT")
        print("=" * 25)
        print("Complete voice training for personalized recognition")
        print()
        
        # Step 1: Record samples
        print("üìù STEP 1: Recording voice samples...")
        if not self.record_voice_samples():
            print("‚ùå Sample recording failed")
            return False
        
        print("\n" + "="*50)
        
        # Step 2: Train wake word
        print("üìù STEP 2: Training wake word...")
        if not self.train_wake_word():
            print("‚ùå Wake word training failed")
            return False
        
        print("\n" + "="*50)
        
        # Step 3: Build profile
        print("üìù STEP 3: Building voice profile...")
        if not self.build_voice_profile():
            print("‚ùå Profile building failed")
            return False
        
        print("\n" + "="*50)
        
        # Step 4: Test recognition
        print("üìù STEP 4: Testing recognition...")
        self.test_recognition()
        
        print("\nüéâ VOICE ENROLLMENT COMPLETE!")
        print("=" * 35)
        print("‚úÖ Your voice model is now trained")
        print("‚úÖ Custom wake word detection ready")
        print("‚úÖ Voice profile integration available")
        print()
        print("üöÄ Next steps:")
        print("   ‚Ä¢ Your PAI voice system will now use your custom profile")
        print("   ‚Ä¢ Try: pai-voice-live-instant for best performance")
        print("   ‚Ä¢ Voice recognition should be more accurate")
        print()
        print("üîÑ To retrain: pai-voice-trainer enroll")

def main():
    trainer = PAIVoiceTrainer()
    
    if len(sys.argv) < 2:
        trainer.show_help()
        return
    
    command = sys.argv[1].lower()
    
    if command == "enroll":
        trainer.full_enrollment()
    elif command == "record-samples":
        trainer.record_voice_samples()
    elif command == "train-wake-word":
        trainer.train_wake_word()
    elif command == "build-profile":
        trainer.build_voice_profile()
    elif command == "test-recognition":
        trainer.test_recognition()
    elif command == "show-profile":
        trainer.show_profile_info()
    elif command in ["--help", "-h", "help"]:
        trainer.show_help()
    else:
        print(f"‚ùå Unknown command: {command}")
        trainer.show_help()

if __name__ == "__main__":
    main()
